# Week 5: GANs and Monet Kaggle Mini-Project

This is the mini-project for Week 5 of CSCA 5642: Introduction to Deep Learning.

As part of this project, we will compete in the [Monet Style Image Generation Kaggle competition](https://www.kaggle.com/competitions/gan-getting-started). The primary goal of the competitoin is to build a model that will produce Monet-style images based on "normal" input images.

This type of problem is typically addressed using a GAN (Genrative Adversarial Network) which consists of at least two neural networks: a generator and a discriminator. The generator is used to generate the images, while the discriminator is used to train the generator during model training. For this specific type of problem, which is sometime termed "style transfer", a [CycleGAN](https://www.geeksforgeeks.org/machine-learning/cycle-generative-adversarial-network-cyclegan-2/) us commonly used since it does not need paired data for training.

## Model Architecture Overview

The initial model is a baseline CycleGAN for comparison of model performance in the competition.

A vanilla GAN typically consists of a generator and discriminator. The generator part of the GAN is trained to generate images that the discriminator labels as "real" or "fake". Input to the generator is "noise" from latent space, and the discriminator compares the generated images with real images to determine whether the generated images are "real".

Our challenge has a slightly different goal - we need to build and train a model to generate a given image with a style that it's trained to use - in this case, Monet style paintings. As hinted at in the challenge description, a CycleGAN can be used to solve this type of problem.

A CycleGAN is similar to a traditional GAN in that is has the concept of generator and discriminator, but the CycleGAN uses two of each.

* Generator A: takes input images from domain X and translates them into domain Y
* Generator B: takes input images from domain Y and translates them into domain X
* Discriminator A: decides on fake vs. real for images from domain X and images generated by Generator B
* Discriminator B: decides on fake vs. real for images from domain Y and images generated by Generator A

More robust `U-Net` and `PatchGAN` architectures based on canonical designs are used subsequent model tests for better scores and visual results.

## Results Summary

Canonical model architectures with robust regularization and random initialization performed best in the overall CycleGAN due to much better regularization at all layers, along with skip connections in the generator (U-Net) models.

# Project References

* Local GitHub notebook: xxx
* Kaggle notebook: https://www.kaggle.com/code/lynchrl/week-5-gan-mini-project-final-execution
